# Crawlerr FastMCP Server Configuration

# Docker Service Ports
# Qdrant ports and settings
QDRANT_GRPC_PORT=7001
QDRANT_HTTP_PORT=7000
QDRANT_LOG_LEVEL=INFO

# TEI port
TEI_HTTP_PORT=8080

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8010
DEBUG=false
PRODUCTION=false

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=console
LOG_TO_FILE=false
# LOG_FILE=/var/log/crawlerr/server.log

# Qdrant Vector Database
QDRANT_URL=http://localhost:7000
# QDRANT_API_KEY=your_api_key_here
QDRANT_COLLECTION=crawlerr_documents
QDRANT_VECTOR_SIZE=1024
QDRANT_DISTANCE=cosine
QDRANT_TIMEOUT=10.0
QDRANT_RETRY_COUNT=3

# Vector Service Configuration
# Enable modular vector service implementation (default: false)
# Set to true to use the new modular architecture for better maintainability
USE_MODULAR_VECTORS=true

# HF Text Embeddings Inference (TEI)
TEI_URL=http://localhost:8080
TEI_MODEL=Qwen/Qwen3-Embedding-0.6B
TEI_MAX_CONCURRENT_REQUESTS=128
TEI_MAX_BATCH_TOKENS=32768
TEI_BATCH_SIZE=64
TEI_TIMEOUT=30.0

# Embedding Configuration
EMBEDDING_MAX_LENGTH=32000
EMBEDDING_DIMENSION=1024
EMBEDDING_NORMALIZE=true
EMBEDDING_MAX_RETRIES=2
EMBEDDING_WORKERS=4

# Reranker Configuration
RERANKER_MODEL=tomaarsen/Qwen3-Reranker-0.6B-seq-cls
RERANKER_ENABLED=true
RERANKER_TOP_K=10
RERANKER_MAX_LENGTH=512
RERANKER_FALLBACK_TO_CUSTOM=true

# Basic Crawling Configuration
CRAWL_HEADLESS=true
CRAWL_BROWSER=chromium
CRAWL_MAX_PAGES=100
CRAWL_MAX_DEPTH=3
MAX_CONCURRENT_CRAWLS=25
CRAWLER_DELAY=0.1
CRAWLER_TIMEOUT=15.0
CRAWL_MIN_WORDS=100
CRAWL_REMOVE_OVERLAYS=true
CRAWL_EXTRACT_MEDIA=false
CRAWL_KNOWLEDGE_GRAPH=false
CRAWL_USER_AGENT="Crawlerr/0.1.0 (+https://github.com/user/crawlerr)"

# Crawl4AI 0.7.0 Advanced Features
CRAWL_ADAPTIVE_MODE=true
CRAWL_CONFIDENCE_THRESHOLD=0.8
CRAWL_TOP_K_LINKS=5
CRAWL_URL_SEEDING=true
CRAWL_SCORE_THRESHOLD=0.4
CRAWL_VIRTUAL_SCROLL=true
CRAWL_SCROLL_COUNT=20
CRAWL_MEMORY_THRESHOLD=90.0

# Browser Configuration
BROWSER_HEADLESS=true
BROWSER_TYPE=chromium
BROWSER_VERBOSE=false
# BROWSER_EXTRA_ARGS=["--no-sandbox","--disable-dev-shm-usage"]
# BROWSER_HARDWARE_PROFILE=rtx4070_i7  # Optional: Enable hardware-specific optimizations

# CORS & Security
CORS_ORIGINS=*
CORS_CREDENTIALS=true
MAX_REQUEST_SIZE=10485760
REQUEST_TIMEOUT=30.0

# GitHub Webhook Server Configuration
# Required: GitHub webhook secret (set in GitHub organization settings)
GITHUB_WEBHOOK_SECRET=your-webhook-secret-here

# Required: GitHub token for API access
GITHUB_TOKEN=ghp_your-github-token-here

# Webhook server port (different from main server)
WEBHOOK_PORT=38080

# Repository filtering
# Use '*' to track all repositories, or comma-separated list: "owner/repo1,owner/repo2"
REPOS_TO_TRACK=*

# Webhook processing configuration
WEBHOOK_SCRIPT_PATH=./scripts/extract_coderabbit_prompts.py
WEBHOOK_OUTPUT_DIR=./webhook_outputs
WEBHOOK_MAX_CONCURRENT_PROCESSES=5

# Event type filtering (true/false)
PROCESS_REVIEWS=true
PROCESS_REVIEW_COMMENTS=true
PROCESS_ISSUE_COMMENTS=true

# Bot patterns to extract content from (comma-separated)
BOT_PATTERNS=coderabbitai[bot],copilot-pull-request-reviewer[bot],Copilot
